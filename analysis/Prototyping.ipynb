{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1453\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('../../reddit-engagement-files/activity.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('''SELECT * FROM activity;''')\n",
    "results = cursor.fetchall()\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP For Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1453\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>access_time</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l9c06q</td>\n",
       "      <td>Avergage people are just as greedy as rich peo...</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l9bayq</td>\n",
       "      <td>Obese people infuriate me.</td>\n",
       "      <td>TrueOffMyChest</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l90oq6</td>\n",
       "      <td>I am proud to do my part in paying forward our...</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l8xsfa</td>\n",
       "      <td>Cool, but why would they bother telling us?</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kzul59</td>\n",
       "      <td>There is absolutely no goddamn reason why you ...</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  l9c06q  Avergage people are just as greedy as rich peo...   \n",
       "1  l9bayq                         Obese people infuriate me.   \n",
       "2  l90oq6  I am proud to do my part in paying forward our...   \n",
       "3  l8xsfa        Cool, but why would they bother telling us?   \n",
       "4  kzul59  There is absolutely no goddamn reason why you ...   \n",
       "\n",
       "          subreddit          access_time action  \n",
       "0  unpopularopinion  01/31/2021 20:39:56   down  \n",
       "1    TrueOffMyChest  01/31/2021 20:39:56   down  \n",
       "2    wallstreetbets  01/31/2021 20:39:56   down  \n",
       "3    wallstreetbets  01/31/2021 20:39:56   down  \n",
       "4  unpopularopinion  01/31/2021 20:39:56   down  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_sql_query('SELECT * FROM activity;', conn)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text) # remove urls\n",
    "    text = re.sub(r'[0-9]+', '', text) # remove numbers\n",
    "    # remove emojis\n",
    "    # remove stop words\n",
    "    # remove special characters\n",
    "    # expand contractions\n",
    "    # tokenize\n",
    "    \n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catcat\n"
     ]
    }
   ],
   "source": [
    "preprocess('9cat0cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
