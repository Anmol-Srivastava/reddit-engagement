{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anmol/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/anmol/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/anmol/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import fire\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DB_RESULTS = '../../reddit-engagement-files/results.db'\n",
    "FOLLOWED_SUBS = ['codcompetitive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # remove urls/numbers\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    # expand contractions\n",
    "    text = re.sub(r\"'ve'\", ' have', text)\n",
    "    text = re.sub(r\"n't\", ' not', text)\n",
    "    # remove emojis and special characters\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U0001F1F2\"\n",
    "        u\"\\U0001F1F4\"\n",
    "        u\"\\U0001F620\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    text = re.sub('[^a-zA-Z0-9]+', ' ', text)\n",
    "    # remove stop words\n",
    "    stops = stopwords.words('english')\n",
    "    text = ' '.join([x for x in text.split() if x not in stops])\n",
    "    # tokenize and lemmatize\n",
    "    text = word_tokenize(text)\n",
    "    lm = WordNetLemmatizer()\n",
    "    text = [lm.lemmatize(x) for x in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_activity(db_path):\n",
    "    connection = None\n",
    "    # exploring ways to ensure file not open elsewhere\n",
    "    try:\n",
    "        with open(db_path, 'r') as _:\n",
    "            connection = sqlite3.connect(db_path)\n",
    "    except IOError:\n",
    "        print('In use / other issue accessing %s' % db_path)\n",
    "    # sort by date and preserve other ordering, return subset\n",
    "    select_all = ''' SELECT * FROM activity;'''\n",
    "    df = pd.read_sql_query(select_all, connection)\n",
    "    df.access_time = pd.to_datetime(df.access_time)\n",
    "    df = df.reset_index().sort_values(by=['access_time', 'index'])\n",
    "    df = df[df.subreddit.apply(lambda x: x.lower() not in FOLLOWED_SUBS)]\n",
    "    df = df.drop(['index'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_from_df(df):\n",
    "    # combine all X somehow\n",
    "    # combine all Y somehow\n",
    "    # countvectorize\n",
    "    # binary classification\n",
    "    # f1-score\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['new'] = df.title.apply(lambda x: preprocess_text(x))\n",
    "# df['vote'] = df.action.apply(lambda x: 0 if x=='down' else 1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>access_time</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>ldjlkr</td>\n",
       "      <td>Change my mind, but without science</td>\n",
       "      <td>clevercomebacks</td>\n",
       "      <td>2021-02-06 12:00:04</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>ldq6lk</td>\n",
       "      <td>AC Valhalla now has 9 Armor sets in the Microt...</td>\n",
       "      <td>pcgaming</td>\n",
       "      <td>2021-02-06 12:00:04</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>ldwd4n</td>\n",
       "      <td>N95</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>2021-02-06 12:00:04</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>ldwt5j</td>\n",
       "      <td>My son always texts to say he's on his way hom...</td>\n",
       "      <td>aww</td>\n",
       "      <td>2021-02-06 12:00:04</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>ldtgfa</td>\n",
       "      <td>Marriage is an outdated institution that gener...</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>2021-02-06 12:00:08</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "1548  ldjlkr                Change my mind, but without science   \n",
       "1549  ldq6lk  AC Valhalla now has 9 Armor sets in the Microt...   \n",
       "1550  ldwd4n                                                N95   \n",
       "1551  ldwt5j  My son always texts to say he's on his way hom...   \n",
       "1552  ldtgfa  Marriage is an outdated institution that gener...   \n",
       "\n",
       "             subreddit         access_time action  \n",
       "1548   clevercomebacks 2021-02-06 12:00:04     up  \n",
       "1549          pcgaming 2021-02-06 12:00:04     up  \n",
       "1550          facepalm 2021-02-06 12:00:04     up  \n",
       "1551               aww 2021-02-06 12:00:04     up  \n",
       "1552  unpopularopinion 2021-02-06 12:00:08   down  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_activity('../../reddit-engagement-files/activity.db')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
