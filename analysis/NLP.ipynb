{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anmol/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/anmol/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/anmol/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import fire\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DB_RESULTS = '../../reddit-engagement-files/results.db'\n",
    "FOLLOWED_SUBS = ['codcompetitive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # remove urls/numbers\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    # expand contractions\n",
    "    text = re.sub(r\"'ve'\", ' have', text)\n",
    "    text = re.sub(r\"n't\", ' not', text)\n",
    "    # remove emojis and special characters\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U0001F1F2\"\n",
    "        u\"\\U0001F1F4\"\n",
    "        u\"\\U0001F620\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    text = re.sub('[^a-zA-Z0-9]+', ' ', text)\n",
    "    # remove stop words\n",
    "    stops = stopwords.words('english')\n",
    "    text = ' '.join([x for x in text.split() if x not in stops])\n",
    "    # tokenize and lemmatize\n",
    "    text = word_tokenize(text)\n",
    "    lm = WordNetLemmatizer()\n",
    "    text = [lm.lemmatize(x) for x in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_activity_batch(db_path, start, end):\n",
    "    connection = None\n",
    "    # exploring ways to ensure file not open elsewhere\n",
    "    try:\n",
    "        with open(db_path, 'r') as _:\n",
    "            connection = sqlite3.connect(db_path)\n",
    "    except IOError:\n",
    "        print('In use / other issue accessing %s' % db_path)\n",
    "    # sort by date and preserve other ordering, return subset\n",
    "    select_all = ''' SELECT * FROM activity;'''\n",
    "    df_batch = pd.read_sql_query(select_all, connection)\n",
    "    df_batch.access_time = pd.to_datetime(df_batch.access_time)\n",
    "    df_batch = df_batch.reset_index().sort_values(by=['access_time', 'index'])\n",
    "    df_batch = df_batch[df_batch.subreddit.apply(lambda x: x.lower() not in FOLLOWED_SUBS)]\n",
    "    df_batch = df_batch.drop(['index'], axis=1)\n",
    "    return df_batch[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_on_batch(df_batch):\n",
    "    # combine all X somehow\n",
    "    # combine all Y somehow\n",
    "    # countvectorize\n",
    "    # binary classification\n",
    "    # f1-score\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP For Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>access_time</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l9c06q</td>\n",
       "      <td>Avergage people are just as greedy as rich peo...</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l9bayq</td>\n",
       "      <td>Obese people infuriate me.</td>\n",
       "      <td>TrueOffMyChest</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l90oq6</td>\n",
       "      <td>I am proud to do my part in paying forward our...</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l8xsfa</td>\n",
       "      <td>Cool, but why would they bother telling us?</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kzul59</td>\n",
       "      <td>There is absolutely no goddamn reason why you ...</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kwf3ub</td>\n",
       "      <td>Apple launches major new Racial Equity and Jus...</td>\n",
       "      <td>apple</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kurmrg</td>\n",
       "      <td>I wonder how many pros consider GAing pros?</td>\n",
       "      <td>CoDCompetitive</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ktf66r</td>\n",
       "      <td>Latinx is bullshit</td>\n",
       "      <td>TrueOffMyChest</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>krk1c0</td>\n",
       "      <td>Why is it a taboo to criticize cultures that d...</td>\n",
       "      <td>TooAfraidToAsk</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>krhja1</td>\n",
       "      <td>CMV: The white teen who said the n word on a S...</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  l9c06q  Avergage people are just as greedy as rich peo...   \n",
       "1  l9bayq                         Obese people infuriate me.   \n",
       "2  l90oq6  I am proud to do my part in paying forward our...   \n",
       "3  l8xsfa        Cool, but why would they bother telling us?   \n",
       "4  kzul59  There is absolutely no goddamn reason why you ...   \n",
       "5  kwf3ub  Apple launches major new Racial Equity and Jus...   \n",
       "6  kurmrg        I wonder how many pros consider GAing pros?   \n",
       "7  ktf66r                                 Latinx is bullshit   \n",
       "8  krk1c0  Why is it a taboo to criticize cultures that d...   \n",
       "9  krhja1  CMV: The white teen who said the n word on a S...   \n",
       "\n",
       "          subreddit          access_time action  \n",
       "0  unpopularopinion  01/31/2021 20:39:56   down  \n",
       "1    TrueOffMyChest  01/31/2021 20:39:56   down  \n",
       "2    wallstreetbets  01/31/2021 20:39:56   down  \n",
       "3    wallstreetbets  01/31/2021 20:39:56   down  \n",
       "4  unpopularopinion  01/31/2021 20:39:56   down  \n",
       "5             apple  01/31/2021 20:39:56   down  \n",
       "6    CoDCompetitive  01/31/2021 20:39:56   down  \n",
       "7    TrueOffMyChest  01/31/2021 20:39:56   down  \n",
       "8    TooAfraidToAsk  01/31/2021 20:39:56   down  \n",
       "9      changemyview  01/31/2021 20:39:56   down  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_sql_query('SELECT * FROM activity;', conn)\n",
    "print(len(df))\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>access_time</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>ldemd0</td>\n",
       "      <td>Nope, not in the great US of A!</td>\n",
       "      <td>WhitePeopleTwitter</td>\n",
       "      <td>02/05/2021 21:00:04</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>ldekzg</td>\n",
       "      <td>Steph and Ayesha Curry Have Quietly Served Up ...</td>\n",
       "      <td>UpliftingNews</td>\n",
       "      <td>02/05/2021 21:00:04</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>ldbhtp</td>\n",
       "      <td>But but but the trickle</td>\n",
       "      <td>PoliticalHumor</td>\n",
       "      <td>02/05/2021 21:00:04</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>ld8c35</td>\n",
       "      <td>Remaster of the Mass Effect games changes some...</td>\n",
       "      <td>SubredditDrama</td>\n",
       "      <td>02/05/2021 21:00:04</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "1539  ldemd0                    Nope, not in the great US of A!   \n",
       "1540  ldekzg  Steph and Ayesha Curry Have Quietly Served Up ...   \n",
       "1541  ldbhtp                            But but but the trickle   \n",
       "1542  ld8c35  Remaster of the Mass Effect games changes some...   \n",
       "\n",
       "               subreddit          access_time action  \n",
       "1539  WhitePeopleTwitter  02/05/2021 21:00:04     up  \n",
       "1540       UpliftingNews  02/05/2021 21:00:04     up  \n",
       "1541      PoliticalHumor  02/05/2021 21:00:04     up  \n",
       "1542      SubredditDrama  02/05/2021 21:00:04     up  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = df.tail(n=10).copy()\n",
    "c[c.subreddit.apply(lambda x: x.lower() not in ['codcompetitive'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/anmol/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/anmol/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/anmol/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor here\n",
    "def preprocess_text(text):\n",
    "    # remove urls/numbers\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    # expand contractions\n",
    "    text = re.sub(r\"'ve'\", ' have', text)\n",
    "    text = re.sub(r\"n't\", ' not', text)\n",
    "    # remove emojis and special characters\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U0001F1F2\"\n",
    "        u\"\\U0001F1F4\"\n",
    "        u\"\\U0001F620\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    text = re.sub('[^a-zA-Z0-9]+', ' ', text)\n",
    "    # remove stop words\n",
    "    stops = stopwords.words('english')\n",
    "    text = ' '.join([x for x in text.split() if x not in stops])\n",
    "    # tokenize\n",
    "    text = word_tokenize(text)\n",
    "    lm = WordNetLemmatizer()\n",
    "    text = [lm.lemmatize(x) for x in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>access_time</th>\n",
       "      <th>action</th>\n",
       "      <th>new</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l9c06q</td>\n",
       "      <td>Avergage people are just as greedy as rich peo...</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "      <td>[avergage, people, greedy, rich, people]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l9bayq</td>\n",
       "      <td>Obese people infuriate me.</td>\n",
       "      <td>TrueOffMyChest</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "      <td>[obese, people, infuriate]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l90oq6</td>\n",
       "      <td>I am proud to do my part in paying forward our...</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "      <td>[proud, part, paying, forward, good, fortune, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l8xsfa</td>\n",
       "      <td>Cool, but why would they bother telling us?</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "      <td>[cool, would, bother, telling, u]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kzul59</td>\n",
       "      <td>There is absolutely no goddamn reason why you ...</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>01/31/2021 20:39:56</td>\n",
       "      <td>down</td>\n",
       "      <td>[absolutely, goddamn, reason, kid]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>ldpl62</td>\n",
       "      <td>They should scrap the current CDL camos and ju...</td>\n",
       "      <td>CoDCompetitive</td>\n",
       "      <td>02/06/2021 01:00:04</td>\n",
       "      <td>up</td>\n",
       "      <td>[scrap, current, cdl, camo, hire, vlionman, wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>ldrx5l</td>\n",
       "      <td>240p vs 1080p</td>\n",
       "      <td>CoDCompetitive</td>\n",
       "      <td>02/06/2021 10:00:03</td>\n",
       "      <td>up</td>\n",
       "      <td>[p, v, p]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>ldsvnf</td>\n",
       "      <td>Karen6 is in shambles rn</td>\n",
       "      <td>CoDCompetitive</td>\n",
       "      <td>02/06/2021 10:00:03</td>\n",
       "      <td>up</td>\n",
       "      <td>[karen, shamble, rn]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>ldv3wi</td>\n",
       "      <td>Petition to vLionMan make the CDL weapon skins...</td>\n",
       "      <td>CoDCompetitive</td>\n",
       "      <td>02/06/2021 10:00:03</td>\n",
       "      <td>up</td>\n",
       "      <td>[petition, vlionman, make, cdl, weapon, skin, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>ldvviw</td>\n",
       "      <td>Just two goats looking at each other</td>\n",
       "      <td>CoDCompetitive</td>\n",
       "      <td>02/06/2021 10:00:03</td>\n",
       "      <td>up</td>\n",
       "      <td>[two, goat, looking]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1548 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0     l9c06q  Avergage people are just as greedy as rich peo...   \n",
       "1     l9bayq                         Obese people infuriate me.   \n",
       "2     l90oq6  I am proud to do my part in paying forward our...   \n",
       "3     l8xsfa        Cool, but why would they bother telling us?   \n",
       "4     kzul59  There is absolutely no goddamn reason why you ...   \n",
       "...      ...                                                ...   \n",
       "1543  ldpl62  They should scrap the current CDL camos and ju...   \n",
       "1544  ldrx5l                                      240p vs 1080p   \n",
       "1545  ldsvnf                           Karen6 is in shambles rn   \n",
       "1546  ldv3wi  Petition to vLionMan make the CDL weapon skins...   \n",
       "1547  ldvviw               Just two goats looking at each other   \n",
       "\n",
       "             subreddit          access_time action  \\\n",
       "0     unpopularopinion  01/31/2021 20:39:56   down   \n",
       "1       TrueOffMyChest  01/31/2021 20:39:56   down   \n",
       "2       wallstreetbets  01/31/2021 20:39:56   down   \n",
       "3       wallstreetbets  01/31/2021 20:39:56   down   \n",
       "4     unpopularopinion  01/31/2021 20:39:56   down   \n",
       "...                ...                  ...    ...   \n",
       "1543    CoDCompetitive  02/06/2021 01:00:04     up   \n",
       "1544    CoDCompetitive  02/06/2021 10:00:03     up   \n",
       "1545    CoDCompetitive  02/06/2021 10:00:03     up   \n",
       "1546    CoDCompetitive  02/06/2021 10:00:03     up   \n",
       "1547    CoDCompetitive  02/06/2021 10:00:03     up   \n",
       "\n",
       "                                                    new  vote  \n",
       "0              [avergage, people, greedy, rich, people]     0  \n",
       "1                            [obese, people, infuriate]     0  \n",
       "2     [proud, part, paying, forward, good, fortune, ...     0  \n",
       "3                     [cool, would, bother, telling, u]     0  \n",
       "4                    [absolutely, goddamn, reason, kid]     0  \n",
       "...                                                 ...   ...  \n",
       "1543  [scrap, current, cdl, camo, hire, vlionman, wo...     1  \n",
       "1544                                          [p, v, p]     1  \n",
       "1545                               [karen, shamble, rn]     1  \n",
       "1546  [petition, vlionman, make, cdl, weapon, skin, ...     1  \n",
       "1547                               [two, goat, looking]     1  \n",
       "\n",
       "[1548 rows x 7 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new'] = df.title.apply(lambda x: preprocess_text(x))\n",
    "df['vote'] = df.action.apply(lambda x: 0 if x=='down' else 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[avergage, people, greedy, rich, people]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[obese, people, infuriate]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[proud, part, paying, forward, good, fortune, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[cool, would, bother, telling, u]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[absolutely, goddamn, reason, kid]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>[scrap, current, cdl, camo, hire, vlionman, wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>[p, v, p]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>[karen, shamble, rn]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>[petition, vlionman, make, cdl, weapon, skin, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>[two, goat, looking]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1548 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    new  vote\n",
       "0              [avergage, people, greedy, rich, people]     0\n",
       "1                            [obese, people, infuriate]     0\n",
       "2     [proud, part, paying, forward, good, fortune, ...     0\n",
       "3                     [cool, would, bother, telling, u]     0\n",
       "4                    [absolutely, goddamn, reason, kid]     0\n",
       "...                                                 ...   ...\n",
       "1543  [scrap, current, cdl, camo, hire, vlionman, wo...     1\n",
       "1544                                          [p, v, p]     1\n",
       "1545                               [karen, shamble, rn]     1\n",
       "1546  [petition, vlionman, make, cdl, weapon, skin, ...     1\n",
       "1547                               [two, goat, looking]     1\n",
       "\n",
       "[1548 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy = df[['new', 'vote']]\n",
    "Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_text = CountVectorizer(\"haven't heard of wouldn't\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                input=\"haven't heard of wouldn't\", lowercase=True, max_df=1.0,\n",
       "                max_features=None, min_df=1, ngram_range=(1, 1),\n",
       "                preprocessor=None, stop_words=None, strip_accents=None,\n",
       "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'vocabulary_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-6e21ebd00a97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'vocabulary_'"
     ]
    }
   ],
   "source": [
    "cv_text.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
